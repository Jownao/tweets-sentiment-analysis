{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive Bayes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0bomFgOlcdj"
      },
      "source": [
        "!spacy download pt_core_news_sm # Após instalação, reiniciar o ambiente do colab."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKnYGzeRte1u"
      },
      "source": [
        "import math\n",
        "import os\n",
        "import pickle\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (accuracy_score, classification_report,\n",
        "                             confusion_matrix, precision_recall_fscore_support)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpXzBgu0wvHd"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2Bd-dRTlQMj"
      },
      "source": [
        "import spacy\n",
        "\n",
        "spc = spacy.load(\"pt_core_news_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKwUikp-vWxv",
        "outputId": "22ac1fc9-a97a-429a-f9b1-dfbaf609b7de"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8N-MPjfvium"
      },
      "source": [
        "default_dir = \"/data/\"\n",
        "data_tcc_pos_neg = default_dir+'labeled_data/dataset_label_pos_neg.csv'\n",
        "data_neg_emotions = default_dir+'labeled_data/plutchik_other_emotions.csv'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrTMGudTvmLX"
      },
      "source": [
        "data_base = pd.read_csv(data_tcc_pos_neg)\n",
        "data['type'] = 'with_theme-' + data['sentiment']\n",
        "data[\"cleaned_text\"] = data[[\"cleaned_text\"]].values.astype(\"U\")\n",
        "data = data.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qybgPvSpthRh"
      },
      "source": [
        "stemmer = nltk.stem.snowball.PortugueseStemmer()\n",
        "analyzer = TfidfVectorizer().build_analyzer()\n",
        "\n",
        "def stemmed_words(doc):\n",
        "    return (stemmer.stem(w) for w in analyzer(doc) if w[0]!='@')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2Ry9okJuk2R"
      },
      "source": [
        "def create_splits(data):\n",
        "    test_validation_size = int(0.30*data.shape[0])\n",
        "    train, test = train_test_split(data, test_size=test_validation_size, random_state=42, stratify=data['type'])\n",
        "    return train, test\n",
        "\n",
        "  \n",
        "train, test = create_splits(data)\n",
        "print('Training samples:  ', train.shape[0])\n",
        "print('Test samples:      ', test.shape[0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzduPUmrtiww"
      },
      "source": [
        "vectorizer = TfidfVectorizer(\n",
        "    stop_words=nltk.corpus.stopwords.words('portuguese'), \n",
        "    analyzer=stemmed_words,\n",
        "    min_df=0.0001, \n",
        "    max_features=100, \n",
        "    max_df=0.8,\n",
        "    lowercase=True, \n",
        "    use_idf=True,\n",
        "    ngram_range=(1, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe3L1wZUtkEs"
      },
      "source": [
        "X_train = vectorizer.fit_transform(train['cleaned_text'].values.astype('U'))\n",
        "X_test = vectorizer.transform(test['cleaned_text'].values.astype('U'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5Zp3qq3tlie"
      },
      "source": [
        "# labels = {\n",
        "#     'Positivo' : 0,\n",
        "#     'Negativo' : 1,\n",
        "# }\n",
        "\n",
        "encoding = {\n",
        "    'tristeza': 0,\n",
        "    'medo': 1,\n",
        "    'raiva': 2,\n",
        "    'desprezo' : 3,\n",
        "}\n",
        "\n",
        "\n",
        "y_train = train['sentiment'].map(labels).values\n",
        "y_test = test['sentiment'].map(labels).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnU5T4G-tqQN"
      },
      "source": [
        "nb = MultinomialNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred = nb.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipjM8o0itue_"
      },
      "source": [
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dPflo_IuQTG"
      },
      "source": [
        "ax = sns.heatmap(confusion_matrix(y_test, y_pred), cmap='Greens_r', annot=True, fmt='d')\n",
        "_ = ax.set(xlabel='Previsto', ylabel='Correto', title='Naive Bayes.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_7G7khTt8E5"
      },
      "source": [
        "#Calculando a acurácia\n",
        "acc = accuracy_score(y_pred, y_test)\n",
        "precision, recall, fscore = precision_recall_fscore_support(y_pred, y_test, average=\"weighted\")\n",
        "print(f'Acurácia: {acc}')\n",
        "print(f'\\nPrecision: {precision} \\n Recall: {recall}\\n FScore: {fscore}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}